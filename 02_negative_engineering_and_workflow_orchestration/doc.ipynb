{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Workflow Orchestration \n",
    "* Negative Engineering - How Production Data Pipelines can Fail\n",
    "* Consequences of Pipeline Failures\n",
    "* Common Workflow Patterns\n",
    "* Exercise: Native Python Work Example\n",
    "* Presentation: The Need for Workflow Orchestration\n",
    "* Discussion: What Can You Use Workflow Orchestration For?\n",
    "* Q&A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Orchestration\n",
    "\n",
    "Workflow orchestration frameworks are primarily used to monitor and observe the movement of data in production applications. Such frameworks typically include a family of independent features that collectively make modern data pipelines fault-tolerant and robust. These features include:\n",
    "\n",
    "* scheduling and triggering jobs\n",
    "* retrying failed work\n",
    "* dependency and state management\n",
    "* caching expensive tasks\n",
    "* resource management\n",
    "* observability\n",
    "\n",
    "These allow us to gracefully handle failure events, including scenarios beyond our control like cloud outages or API failures. Without explicitly tracking states in data pipelines, they become prone to triggering premature jobs, re-running already completed work, or even failing haphazardly. \n",
    "\n",
    "The features workflow orchestration provides are not limited to supporting the scheduled movement of data from a source to a destination. These features are also heavily applied in other domains such as machine learning and parameterized report generation. Presently, workflow orchestration is getting simple enough for hobbyists to adopt for personal projects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Engineering\n",
    "Negative Engineering happens when engineers write defensive code to make sure the positive code acutally runs. Writing code that anticipates the infinite number of possible failures.\n",
    "\n",
    "#### Why this matters to you\n",
    "- contiually patching of legacy pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consequences of pipeline failures\n",
    "* time spent finding where in the pipeline the failure occurred\n",
    "* premature job triggers\n",
    "* data staleness \n",
    "* expensive compute rerunning tasks \n",
    "* duplicating work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common workflow patterns\n",
    "\n",
    "- ETL \n",
    "- ELT\n",
    "- ML\n",
    "- Dashboarding\n",
    "- DevOps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Native Python Work Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import httpx\n",
    "\n",
    "def get_stars(repo: str):\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    count = httpx.get(url).json()[\"stargazers_count\"]\n",
    "    print(f\"{repo} has {count} stars!\")\n",
    "\n",
    "\n",
    "def github_stars(repos: List[str]):\n",
    "    for repo in repos:\n",
    "        get_stars(repo)\n",
    "\n",
    "github_stars([\"PrefectHQ/Prefect\", \"PrefectHQ/miter-design\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion: What Can You Use Workflow Orchestration For?\n",
    "\n",
    "For Funsies:\n",
    "- March Madness brackets\n",
    "- Notification on shoe prices \n",
    "- Turning off your lights (us not being lazy)\n",
    "- Notifications on crypto "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q&A"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
