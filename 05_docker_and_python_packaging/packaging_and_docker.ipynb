{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker and Python Packaging\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://miro.medium.com/max/504/1*iBGlEPUruUqqT5NreeEF8g.png\" width=200>\n",
    "</center>\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Data professionals often hear phrases like \"it worked on my machine\" or \"nothing changed, but by workflow stopped running.\"\n",
    "\n",
    "You might already be familiar with virtual environments. Virtual environment managers such as `poetry`, `pipenv`, and `conda` are useful since they allow us to fix package versions. \n",
    "\n",
    "\n",
    "Simiarly, Docker allows us to build images and run them in other execution environments. An image contains all of the dependencies needed for our application, while a container is an instance of the image. By building a fixed image, we can pin the dependencies so that they stay fixed from run to run. \n",
    "\n",
    "## What are some reasons to be using **docker**?\n",
    "\n",
    "- We can manage processes needing different Python versions on different containers!\n",
    "\n",
    "- It allows us to include non-Python dependencies in our runtime, such as C compilers or Java for Spark\n",
    "\n",
    "- Encourages reproducible work and lightweight runtimes (exactly what we need &mdash; nothing more, nothing less)\n",
    "\n",
    "- Eases the transition from development to deployment\n",
    "\n",
    "- Containerized environments are the standard within scalable frameworks like kubernetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Architecture\n",
    "\n",
    "The Aqua Security [documentation](https://www.aquasec.com/cloud-native-academy/docker-container/docker-architecture/) has a very good diagram about the Docker architecture. There are three main parts:\n",
    "\n",
    "* Client - this can be the Docker client or Python client\n",
    "\n",
    "* Daemon - the daemon is what orchestrates containers and images\n",
    "\n",
    "* Registry - used to house images that we can pull down from other places\n",
    "\n",
    "![img](docker_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a sample project...\n",
    "\n",
    "Alongside this notebook, there is a folder named `docker_with_custom_module`. \n",
    "\n",
    "It represents a Prefect Flow that uses custom modules defined by the user. \n",
    "\n",
    "Packaging custom code as a Python modules allows us to run with from any directory within the container, as well as reuse it in other projects more easily. \n",
    "\n",
    "Using this folder, we will build a custom Docker image to support our Flow. The directory structure is like:\n",
    "\n",
    "```\n",
    "docker_with_custom_module/\n",
    "â”œâ”€â”€ components/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ componentA.py\n",
    "â”‚   â”œâ”€â”€ componentB.py\n",
    "â”œâ”€â”€ workflow/\n",
    "â”‚   â”œâ”€â”€ custom_flow.py\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â”œâ”€â”€ Dockerfile\n",
    "â””â”€â”€ setup.py\n",
    "```\n",
    "\n",
    "and a brief description of each of the components:\n",
    "\n",
    "* `components/*.py` - contains the custom code that will be used in multiple flows\n",
    "\n",
    "* `workflow/` - contains the Prefect flow\n",
    "\n",
    "* `requirements.txt` - dependencies of the project\n",
    "\n",
    "* `Dockerfile` - the instructions to package this folder into a Docker image\n",
    "\n",
    "* `setup.py` - `pip` looks at this file for instructions how to install the module\n",
    "\n",
    "### What if we want to use custom Python code in our container?\n",
    "\n",
    "The components are very simple Python classes. Imagine they're mission-critical custom python modules that we want to use in a production Prefect flow.\n",
    "\n",
    " Below is `componentA.py`:\n",
    "\n",
    "```python\n",
    "class ComponentA:\n",
    "    def __init__(self, n=2) -> None:\n",
    "        self.n = n\n",
    "```\n",
    "\n",
    "... `componentB.py` being very similar.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Now, let's look at the `custom_flow.py` in the `workflow` folder. This just imports the components and uses them inside a task.\n",
    "\n",
    "```python\n",
    "from prefect import flow, task\n",
    "\n",
    "from components.componentA import ComponentA \n",
    "from components.componentB import ComponentB\n",
    "\n",
    "@task\n",
    "def custom_task():\n",
    "    x = ComponentA(2)\n",
    "    y = ComponentB(2)\n",
    "    _sum = x.n + y.n\n",
    "    print(f\"Test {_sum}!\")  # Should return 4\n",
    "    return _sum\n",
    "\n",
    "@flow\n",
    "def custom_flow():\n",
    "    custom_task()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a module with a `setup.py`\n",
    "\n",
    "Importing these custom modules works all well and dandy without docker when we run our code locally.\n",
    "\n",
    "However, in order to package the `components` as a portable module, we need to add the `__init__.py` file inside the folder. The package name and version are used by pip to keep track of the package, but they donâ€™t affect how the package is used in Python code. \n",
    "\n",
    "The `find_packages()` function call goes through the subdirectories with an `__init__.py` and includes them in `mypackage`. \n",
    "\n",
    "Notice this file takes care of installing the requirements &mdash; the  `setup()` function is the one `pip` looks for in order to install the library:\n",
    "\n",
    "```python\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "with open('requirements.txt') as f:\n",
    "    requirements = f.read().splitlines()\n",
    "\n",
    "setup(\n",
    "    name=\"mypackage\",\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    install_requires=requirements\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the custom module\n",
    "\n",
    "With this file written, we can now install the library by doing,\n",
    "\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "and this lets us import `components` from other directories because the Python path can resolve it.\n",
    "\n",
    "## Building the Docker image\n",
    "\n",
    "Now that we have the custom module installed, we want to create the Docker image so that we can run it in other execution environments. \n",
    "\n",
    "```Dockerfile\n",
    "FROM prefecthq/prefect:latest\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "ADD . .\n",
    "\n",
    "RUN pip install .\n",
    "```\n",
    "\n",
    "<div style=\"background-color: #70c6ff;border-radius: 10px;padding: 20px;\">\n",
    "\n",
    "ðŸ’¡ **note**:\n",
    "\n",
    "context on Dockerfile keywords we used above:\n",
    "\n",
    "`FROM` â€” this is the base image that weâ€™ll build our image on top of\n",
    "\n",
    "\n",
    "`WORKDIR` â€” set the working directory for the container. It will be created if it doesnâ€™t exist\n",
    "\n",
    "\n",
    "`ADD` â€” here we copy all of our files from the current directory to the container `WORKDIR`\n",
    "\n",
    "\n",
    "`RUN` - we can `RUN` a command to add a layer to our image. In this case, those our dependencies from our module\n",
    "\n",
    "</div>\n",
    "\n",
    "In order to build the image, we can run a command like the following:\n",
    "\n",
    "```\n",
    "docker build . -t test:latest\n",
    "```\n",
    "\n",
    "where `test` is the image name and `latest` is the image tag.\n",
    "\n",
    "### Using the image\n",
    "\n",
    "In order to check everything is good, we can run the image interactively,\n",
    "\n",
    "```\n",
    "docker run --name containername -i -t my_image:latest /bin/bash\n",
    "```\n",
    "\n",
    "and from there we should be in the app directory and we can run our flow with:\n",
    "\n",
    "```\n",
    "python workflow/flow.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to a Registry\n",
    "\n",
    "Now that the image has been created, you can push it to your registry (Dockerhub, AWS ECR, etc.) using the `docker push` command. These registries will have different ways to do it but we'll cover how to do it with DockerHub, which is the de facto registry.\n",
    "\n",
    "### Auth\n",
    "We need to auth our CLI session with our image repository otherwisesuperconvenientfreestorage\n",
    "\n",
    "```console\n",
    "docker login\n",
    "```\n",
    "\n",
    "### Build and Tag\n",
    "```console\n",
    "docker build . --tag zzstoatzz/my_image:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the image for a Flow\n",
    "\n",
    "In order to use the image for a flow, we can create a deployment using the `DockerFlowRunner()` with the image that we just uploaded\n",
    "\n",
    "```python\n",
    "from prefect.deployments import DeploymentSpec\n",
    "from prefect.flow_runners import DockerFlowRunner\n",
    "\n",
    "DeploymentSpec(\n",
    "    name=\"docker-example\",\n",
    "    flow=custom_flow,\n",
    "    flow_runner=DockerFlowRunner(\"repo/image\")\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we'll look at advanced patterns for workflow orchestration before doing an end-to-end example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
