{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker and Python Packaging\n",
    "\n",
    "- [How to build a docker image](#how-to-build-a-docker-image)\n",
    "- [Pushing an image to a registry](#how-to-push-an-image-to-a-registry)\n",
    "- [**Exercise**: Build a simple custom image of your own](#exercise-build-your-own-custom-image)\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In the previous section, we saw how to spin up a cluster using Dask. Using a Docker image spins up the workers with a consistent environment so that distributed flows run reliably. But even beyond the use case with Dask, Docker is an integral part of data workflows. Data professionals often hear phrases like \"it worked on my machine\" or \"nothing changed, but by workflow stopped running.\"\n",
    "\n",
    "Docker allows us to build images and run them in other execution environments. An image contains all of the dependencies needed for our application, while a container is an instance of the image. By building a fixed image, we can pin the dependencies so that they stay fixed from run to run. \n",
    "\n",
    "## When to use Docker?\n",
    "\n",
    "Data scientists or data engineers might already be familiar with virtual environments. Virtual environment managers such as `poetry`, `pipenv`, and `conda` allow us to fix package versions. What are the use cases then that call for Docker?\n",
    "\n",
    "1. You can have multiple containers with different Python versions\n",
    "2. It allows us to pin the non-Python dependencies such as Java for Spark\n",
    "3. It is the unit for spinning up clusters/jobs (Kubernetes or Dask)\n",
    "4. Host legacy applications with older technology (some Prefect users run containers with specific scientific computing libraries)\n",
    "5. Encourages reproducible work\n",
    "6. Eases the transition from development to deployment (some services like AWS ECS and Google Vertex need containers to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Architecture\n",
    "\n",
    "The Aqua Security [documentation](https://www.aquasec.com/cloud-native-academy/docker-container/docker-architecture/) has a very good diagram about the Docker architecture. There are three main parts:\n",
    "\n",
    "* Client - this can be the Docker client or Python client\n",
    "* Daemon - the daemon is what orchestrates containers and images\n",
    "* Registry - used to store images for downloading in other places.\n",
    "\n",
    "![img](docker_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Docker image\n",
    "\n",
    "\n",
    "\n",
    "`Dockerfile`\n",
    "```Dockerfile\n",
    "\n",
    "FROM base_image:andmyTag\n",
    "\n",
    "COPY myModule2 /root/or/somewhere_on_my_new_container\n",
    "\n",
    "# and for myModule2's dependencies, we need to\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# and then maybe some commands to run when the container starts, like a\n",
    "CMD echo 'ing some handy dandy message like \"cats!\" or \"im cool!\"'\n",
    "```\n",
    "\n",
    "## Upload to a Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "<!-- https://medium.com/the-prefect-blog/the-simple-guide-to-productionizing-data-workflows-with-docker-31a5aae67c0a -->\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/504/1*iBGlEPUruUqqT5NreeEF8g.png\" width=200>\n",
    "\n",
    "## **Exercise**: dockerizing some python\n",
    "\n",
    "\n",
    "\n",
    "## what is docker?\n",
    "it is an open-source containerization technology especially useful for cloud-based ecosystems\n",
    "\n",
    "## how can we **build** a docker image?\n",
    "we tell docker what to build!\n",
    "\n",
    "`Dockerfile`\n",
    "```Dockerfile\n",
    "# starting\n",
    "FROM base_image:andmyTag\n",
    "\n",
    "COPY myModule2 /root/or/somewhere_on_my_new_container\n",
    "\n",
    "# and for myModule2's dependencies, we need to\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# and then maybe some commands to run when the container starts, like a\n",
    "CMD echo 'ing some handy dandy message like \"cats!\" or \"im cool!\"'\n",
    "```\n",
    "## **push** an image to a registry\n",
    "\n",
    "### Auth\n",
    "<!-- thoughts on actually having people login/signup w dockerhub? -->\n",
    "We need to auth our CLI session with our image repository otherwisesuperconvenientfreestorage\n",
    "\n",
    "```console\n",
    "docker login\n",
    "```\n",
    "sign up etc\n",
    "\n",
    "### Build and Tag\n",
    "```console\n",
    "docker build . --tag zzstoatzz/prefect-imgs:dev\n",
    "```\n",
    "\n",
    "## other cool images (prolly ML stuff) + what they do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup, find_packages\n",
    "\n",
    "# with open('requirements.txt') as f:\n",
    "#     requirements = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker and Python Packaging (25 min) - Nate:\n",
    "* Presentation: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* How to create a Python Package\n",
    "* Uploading an image to a registry\n",
    "* Exercise: Building a simple image\n",
    "* Q&A\n",
    "Resource: https://medium.com/the-prefect-blog/the-simple-guide-to-productionizing-data-workflows-with-docker-31a5aae67c0a\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('new_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bcd5122a16dddddc6d4299690594049573e95f3457fc9cee18f649756d536ee8"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}